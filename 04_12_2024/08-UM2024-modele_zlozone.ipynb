{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119c6ee9",
   "metadata": {},
   "source": [
    "# Ulepszanie wydajności klasyfikatorów\n",
    "\n",
    "Wydajność modeli można zwiększać poprzez:\n",
    "\n",
    "- dostrajanie parametrów pojedynczego modelu w celu jego ulepszenia. Do automatycznego dostrajania parametrów modelu w R można użyć pakietu `caret`. Pełna lista metod (algorytmów uczenia maszynowego) i ich dostosowywalnych parametrów znajduje się na [stronie internetowej](http://topepo.github.io/caret/available-models.html).\n",
    "\n",
    "- łączenie ze sobą kilku słabych modeli w celu utworzenia lepszej jednostki. Jest to tak zwane uczenie zespołowe (ang. *ensemble learning*), któremu poświęcone są dzisiejsze ćwiczenia.\n",
    "\n",
    "## Metody zespołowe\n",
    "\n",
    "Podstawowe założenie: zaangażowanie zespołu różnych ekspertów (modeli) we wspólne rozwiązywanie problemu podniesie wydajność uczenia.\n",
    "\n",
    "### Bagging\n",
    "\n",
    "Jedna z najpopularniejszych technik uczenia zespołowego. Nazwa pochodzi od *bootstrap aggregating* - technika bagging wykorzystuje próbkowanie metodą bootstrap w funkcji alokacji do generowania danych przypisywanych do każdego z modeli w zespole. Zespoły w agregacji bootstrap zazwyczaj składają się z jednorodnych klasyfikatorów, które są trenowane równolegle i niezależnie od siebie.\n",
    "Wśród metod bagging jedną z najpopularniejszych są *lasy losowe* (ang. *random forest*), składające się z wielu klasyfikatorów drzew decyzyjnych. Funkcja alokacji lasów łączy próbkowanie metodą bootstrap z losowym wybieraniem cech do generowania danych przydzielanych każdemu z klasyfikatorów w zespole. Lasy losowe nadają się do obsługiwania bardzo szerokich zbiorów danych.\n",
    "\n",
    "### Boosting\n",
    "\n",
    "Zespoły Wzmacniające (ang. *boosting*) są również jednorodnymi zbiorami podstawowych modeli. W odróżnieniu od agregacji bootstrap, we wzmacnianiu podstawowe modele są trenowane sekwencyjnie. Każdy kolejny model w sekwencji próbuje osiągnąć większą wydajność od poprzedniego modelu, ucząc się na błędach poprzednika. Następnie przeprowadzane jest wtórne próbkowanie danych treningowych tak, że przykładom dla których były nieprawidłowe predykcje, otrzymują większą wagę.\n",
    "\n",
    "Proces wtórnego próbkowania, trenowania, oceniania i punktowania jest powtarzany do każdego modelu w sekwencji, dopóki wszystkie modele nie zostaną wytrenowane.\n",
    "\n",
    "### Stacking\n",
    "\n",
    "Stacking, czyli kontaminacja modeli, różni się od poprzednich dwóch tym, że zawiera tu zwykle różnorodne modele podstawowe. Przykładowo może składać się z modelu kNN, modelu regresji logistycznej oraz naiwnego modelu Bayesa. Kontaminacja modeli jest podobna do agregacji bootstrap, tyle że funkcja kombinacji jest tutaj niedeterministyczna (nie przebiega zgodnie z predefiniowanym wzorcem czy zbiorem reguł).\n",
    "\n",
    "Zazponaj się z materiałami zamieszczonymi na stronie [RPubs](https://rpubs.com/mmazurek/346331), sekcje:\n",
    "\n",
    "- Klasyfikatory złożone\n",
    "\n",
    "- Agregacja bootstrapowa (bagging - bootstrap aggregation)\n",
    "\n",
    "- Lasy losowe\n",
    "\n",
    "- Boosting\n",
    "  - Adaboost - adaptive boosting\n",
    "\n",
    "Następnie wykonaj poniższe zadania.\n",
    "\n",
    "## Zadania\n",
    "\n",
    "1.\tPobierz i wczytaj w RStudio plik z danymi `Movie_classification.csv`. Celem zadania jest przewidzenie, czy dany film otrzyma Oskara czy też nie (zmienna dychotomiczna `Start_Tech_Oskar`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5c42b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bedad5b3",
   "metadata": {},
   "source": [
    "2.\tPrzyglądnij się danym i przygotuj je do dalszej analizy:\n",
    "\n",
    " - braki danych zastąp wartością średnią dla danego atrybutu, \n",
    " - za pomocą funkcji `sample.split` (z pakietu `caTools`) oraz `subset` podziel dane na zbiór treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2db9fa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9459ccf",
   "metadata": {},
   "source": [
    "3. Dokonaj klasyfikacji za pomocą trzech algorytmów złożonych: bagging, random forest oraz boosting (zbuduj modele na zbiorze treningowym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df25f2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355b18e9",
   "metadata": {},
   "source": [
    "4. Sprawdź jak dobrze utworzone modele radzą sobie z danymi testowymi (użyj funkcji `confusionMatrix` z pakietu `caret`). Jaki procent danych został poprawnie zaklasyfikowany? Który model okazał się w tym przypadku najlepszy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90fc95",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R (RKernel)",
   "language": "R",
   "name": "rkernel"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
